{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ],
      "metadata": {
        "id": "kExUKaFbkmAy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Learnable Positional Encoding layer\n",
        "class LearnablePositionalEncoding(nn.Module):\n",
        "  def __init__(self, seq_len, d_model):\n",
        "    super(LearnablePositionalEncoding, self).__init__()\n",
        "    self.positional_encoding = nn.Parameter(torch.zeros(seq_len, d_model))\n",
        "\n",
        "  # add positional encodings\n",
        "  def forward(self, x):\n",
        "    return x + self.positional_encoding\n",
        "\n",
        "  # print positional encodings\n",
        "  def print(self):\n",
        "    print(self.positional_encoding)"
      ],
      "metadata": {
        "id": "Qj_um-GYksvN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dummy Dataset\n",
        "class DummyDataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, num_samples, seq_len, vocab_size):\n",
        "    self.num_samples = num_samples\n",
        "    self.data = torch.randint(0, vocab_size, (num_samples, seq_len))\n",
        "    self.labels = torch.randint(0, 2, (num_samples,))  # Binary labels\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.num_samples\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    return self.data[idx], self.labels[idx]"
      ],
      "metadata": {
        "id": "WGSXME4YlBg5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom Model\n",
        "class CustomModel(nn.Module):\n",
        "  def __init__(self, seq_len, d_model, vocab_size):\n",
        "    super(CustomModel, self).__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, d_model)\n",
        "    self.positional_encoding = LearnablePositionalEncoding(seq_len, d_model)\n",
        "    self.self_attention = nn.MultiheadAttention(d_model, num_heads=4, batch_first=True)\n",
        "    self.fc = nn.Linear(d_model, 2)\n",
        "\n",
        "  # forward\n",
        "  def forward(self, x):\n",
        "    x = self.embedding(x)\n",
        "    x = self.positional_encoding(x)\n",
        "    attn_output, _ = self.self_attention(x, x, x)\n",
        "    x = attn_output.mean(dim=1)\n",
        "    return self.fc(x)"
      ],
      "metadata": {
        "id": "bTc820F1l4lP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyper params\n",
        "num_samples = 1000\n",
        "seq_len = 10\n",
        "vocab_size = 50\n",
        "batch_size = 32\n",
        "d_model = 32\n",
        "num_epochs = 10\n",
        "\n",
        "# dataloader for dummydata\n",
        "dataset = DummyDataset(num_samples=num_samples, seq_len=seq_len, vocab_size=vocab_size)\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# CustomModel Instance\n",
        "model = CustomModel(seq_len, d_model, vocab_size)\n",
        "\n",
        "# CrossEntropy loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Adam optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "eEo5Nh35m2UG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJ0YTrgwKqbP",
        "outputId": "58000ca8-c9a0-48b7-b260-8b8d2b97eabe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CustomModel(\n",
              "  (embedding): Embedding(50, 32)\n",
              "  (positional_encoding): LearnablePositionalEncoding()\n",
              "  (self_attention): MultiheadAttention(\n",
              "    (out_proj): NonDynamicallyQuantizableLinear(in_features=32, out_features=32, bias=True)\n",
              "  )\n",
              "  (fc): Linear(in_features=32, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Positional Encoding before training\n",
        "model.positional_encoding.print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QlJG9WUXu9xI",
        "outputId": "4b04e0c9-8ddb-4df0-bb5b-a152f06db7e2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "         0., 0., 0., 0., 0., 0., 0., 0.]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# traning\n",
        "for epoch in range(num_epochs):\n",
        "    total_loss = 0\n",
        "    for data, labels in dataloader:\n",
        "\n",
        "        # forward pass\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "\n",
        "        loss = criterion(output, labels) # loss\n",
        "\n",
        "        # backword pass\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {total_loss:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lYeavnAIoJt3",
        "outputId": "b9a5b931-01db-4ff5-f74a-429ace508d74"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 22.3550\n",
            "Epoch 2/10, Loss: 22.1789\n",
            "Epoch 3/10, Loss: 21.9619\n",
            "Epoch 4/10, Loss: 21.8773\n",
            "Epoch 5/10, Loss: 21.7146\n",
            "Epoch 6/10, Loss: 21.4730\n",
            "Epoch 7/10, Loss: 21.2953\n",
            "Epoch 8/10, Loss: 21.2298\n",
            "Epoch 9/10, Loss: 20.9922\n",
            "Epoch 10/10, Loss: 20.5630\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Positional Encoding after training\n",
        "model.positional_encoding.print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBUYjAWXvBD8",
        "outputId": "9dfe7240-7d64-4a5f-bf38-a8b63c540b4d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[-3.1466e-03,  6.1018e-03,  2.4692e-03, -3.1287e-02,  1.2773e-02,\n",
            "         -3.0379e-03,  2.0704e-02, -3.4882e-02,  1.6531e-02, -3.0002e-02,\n",
            "         -1.5794e-02,  1.5690e-02, -1.0167e-01, -6.3978e-02, -2.3232e-02,\n",
            "          5.2042e-02, -1.8232e-02,  1.3805e-02, -1.4339e-02,  3.5232e-02,\n",
            "         -1.5111e-02, -5.2531e-03, -2.5525e-02,  4.6537e-02, -1.1457e-04,\n",
            "         -4.1833e-02,  3.7339e-02, -1.4136e-02,  1.2506e-02,  2.3147e-02,\n",
            "         -2.2639e-02, -1.7194e-02],\n",
            "        [-2.4170e-02,  2.7554e-02, -1.2757e-02,  1.8083e-02,  2.8730e-02,\n",
            "         -3.3117e-02, -2.9872e-02, -1.0636e-02,  6.4208e-03,  2.2384e-02,\n",
            "          2.6614e-03,  5.8113e-02, -1.6450e-02, -3.8446e-02,  8.2055e-03,\n",
            "          3.0226e-02,  1.6807e-03, -5.2279e-02, -2.6574e-02,  1.4283e-02,\n",
            "          2.0021e-02, -2.2082e-02,  3.0174e-02,  1.0478e-02, -2.4284e-02,\n",
            "         -4.0875e-02,  2.1014e-02, -2.2329e-02,  2.4974e-02,  1.9988e-02,\n",
            "         -1.0269e-02,  7.1575e-03],\n",
            "        [-1.3432e-02,  1.3430e-02, -5.7941e-03,  1.1702e-02,  3.7799e-02,\n",
            "         -4.0667e-02, -5.1327e-03,  7.4851e-02, -2.2881e-02, -2.7988e-03,\n",
            "          3.2420e-02,  3.9898e-02, -5.8327e-02,  2.7547e-02, -1.9171e-02,\n",
            "          4.4056e-02, -4.3283e-02,  2.6008e-02,  1.6203e-02,  4.0925e-03,\n",
            "         -7.1028e-03,  1.4124e-02,  2.3730e-02,  2.2839e-02, -1.1228e-02,\n",
            "          1.0018e-02, -1.1821e-02, -2.8321e-02,  3.3469e-02,  6.1531e-02,\n",
            "         -4.9544e-02,  2.3066e-02],\n",
            "        [-1.3009e-02,  2.2223e-02, -2.1824e-02,  1.2320e-02, -2.1142e-03,\n",
            "         -2.1696e-02, -4.1204e-03,  2.1738e-02,  7.9279e-03,  4.2361e-03,\n",
            "          6.2510e-03,  4.7648e-03, -6.2202e-02, -3.2178e-02,  1.9604e-02,\n",
            "          7.3692e-03, -7.5992e-03, -1.9699e-03,  1.5297e-02, -1.1872e-02,\n",
            "         -1.8740e-02, -3.3189e-02,  2.3594e-03,  2.4373e-02, -2.8691e-02,\n",
            "         -1.5000e-02, -1.9787e-02, -2.3234e-02,  3.6389e-02,  1.7778e-02,\n",
            "         -2.0253e-02,  3.0899e-03],\n",
            "        [-7.1306e-03,  7.0249e-03, -6.8510e-02, -1.2869e-02,  6.0082e-02,\n",
            "          1.0452e-03, -9.2631e-03,  1.8084e-02,  8.7328e-03,  2.8791e-02,\n",
            "         -4.4638e-02,  4.3587e-02,  4.0894e-02, -1.6075e-02, -4.7368e-02,\n",
            "         -1.1361e-02,  2.0937e-02, -1.1034e-02, -2.5211e-02,  2.9574e-02,\n",
            "          1.6341e-03, -5.1755e-02, -1.3508e-02,  2.1054e-02, -2.5423e-02,\n",
            "         -3.0360e-02,  2.5384e-02, -1.5396e-02,  3.9381e-02,  4.4630e-02,\n",
            "         -1.3654e-02,  1.2420e-02],\n",
            "        [-8.9644e-03,  1.0264e-02,  4.5109e-02,  1.9741e-02,  2.2313e-03,\n",
            "         -8.2408e-03, -4.0263e-02,  1.7489e-02, -9.4115e-03, -2.7063e-02,\n",
            "         -4.3341e-02,  2.4034e-02, -6.9670e-02,  2.9040e-04,  1.2407e-02,\n",
            "          1.7097e-02,  3.1274e-02, -1.7024e-02, -2.1986e-02, -1.1954e-02,\n",
            "          1.2076e-02,  3.0340e-02, -9.6686e-03, -2.6574e-02, -5.0091e-03,\n",
            "         -9.8588e-03,  3.4103e-02, -2.4761e-02, -3.3059e-03,  1.1424e-02,\n",
            "          1.3583e-03,  4.0503e-02],\n",
            "        [-2.9172e-02,  2.3081e-02, -1.8819e-02,  6.8119e-02,  1.7304e-02,\n",
            "         -6.9841e-02, -3.0345e-02,  4.1112e-02, -1.2023e-02, -3.8092e-02,\n",
            "          8.2140e-02,  4.9985e-02, -1.9202e-02, -2.1949e-02,  1.7632e-02,\n",
            "          4.9372e-02, -6.2335e-02,  1.0338e-02,  4.8054e-02, -3.7765e-02,\n",
            "          2.2383e-03, -4.7949e-03,  3.2366e-02,  4.5719e-02, -3.4327e-02,\n",
            "         -9.6878e-03, -3.4595e-02, -4.3617e-02,  4.0586e-02,  6.1822e-02,\n",
            "         -4.5006e-02,  2.2981e-02],\n",
            "        [-1.6482e-02,  3.3736e-02,  5.4812e-02,  8.5848e-03, -5.1906e-02,\n",
            "         -1.4035e-02, -1.2126e-02, -1.2013e-02, -3.9388e-02,  8.0437e-03,\n",
            "         -1.4228e-02,  2.4729e-03, -1.0911e-01, -3.0654e-02, -1.2766e-02,\n",
            "          2.6647e-02,  3.4814e-02,  1.6946e-02, -1.3056e-02,  3.3990e-03,\n",
            "         -1.4561e-02,  3.8973e-02,  1.8391e-02,  3.8122e-02,  1.4197e-03,\n",
            "         -6.7218e-04, -1.3577e-02, -1.2414e-02, -5.8913e-02, -1.1061e-02,\n",
            "         -1.3483e-02,  3.3852e-02],\n",
            "        [-2.9187e-02,  3.4482e-02, -1.4992e-02,  3.7986e-04,  1.0813e-01,\n",
            "          1.2113e-02, -4.8162e-02,  4.0406e-02,  3.3822e-03, -2.3581e-02,\n",
            "         -1.0042e-01,  4.7075e-02, -7.8553e-02, -6.1968e-02, -1.1363e-02,\n",
            "          3.0967e-02,  1.9496e-02,  3.5919e-02, -6.3414e-03, -1.1394e-02,\n",
            "          2.5980e-02,  7.9417e-02, -1.8981e-02, -4.4052e-02, -4.3518e-02,\n",
            "         -3.1726e-02,  3.9235e-02, -2.8203e-02,  2.2446e-02,  2.2667e-05,\n",
            "          5.1409e-02,  6.1107e-02],\n",
            "        [-1.0635e-02,  9.7143e-03,  3.9214e-02,  3.2469e-02, -7.6176e-03,\n",
            "         -2.1721e-02, -3.5961e-02,  9.7026e-03, -1.5887e-02, -5.9691e-02,\n",
            "          4.4839e-02,  7.9872e-02, -7.9491e-03,  1.3661e-02,  3.8923e-02,\n",
            "          2.2497e-02,  2.8096e-02, -1.9398e-02, -2.4944e-02,  6.4938e-04,\n",
            "         -3.9148e-03, -1.6298e-02,  1.6399e-02,  9.9932e-03,  8.1840e-03,\n",
            "         -8.5608e-03, -8.3562e-03, -1.4163e-02, -2.1599e-02, -3.0261e-02,\n",
            "          1.1892e-02,  3.6611e-03]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cIDg_ei5vDQw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}